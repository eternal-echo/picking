# 视觉零件分拣系统毕业设计

## 系统架构
上图展示了整个系统的架构，其中包含三个模块：视频流输入模块、视觉分拣模块和控制输出模块。视频流输入模块负责从相机或者视频文件中获取视频流，传递给视觉分拣模块。视觉分拣模块包含三个子模块：分割、跟踪和识别。在分割子模块中，我们使用了基于背景消融的方法，对视频流进行背景建模和帧差法分割，得到目标的二值蒙版，并通过形态学操作和连通域分析算法找到候选目标。在跟踪子模块中，我们使用了卡尔曼滤波器，结合光流法来估计目标的运动状态，以及一些过滤方法来筛选出真正的目标零件。在识别子模块中，我们使用YOLOv5进行目标识别和分类。最后，控制输出模块根据识别结果，控制执行机械臂进行物品的分拣。

## 方案
1.分割
- 对视频流进行背景建模并使用形态学操作去除噪声。
- 针对候选目标连通域，使用图像处理算法来定位、筛选和过滤不必要的区域。
- 使用光流法检测目标运动方向和速度，并根据预设规则选择合适的目标零件。

2.跟踪
- 使用卡尔曼滤波器对目标状态进行估计和预测，并根据新的测量值进行更新。
- 采集多张目标图片，并利用图像增强技术提高图像质量。

3.识别
- 当目标零件离开视频流的指定区域后，使用yolov5进行识别。

## 重点因素
- 系统需要实时性能，尽可能减少延迟和数据存储。
- 检测和识别的准确性需要达到高水平，因此可能需要使用更复杂的算法或深度学习模型。
- 系统需要具有鲁棒性以应对各种光照条件、目标大小、形状和位置的变化。
- 为方便未来维护和升级，需要设计可扩展和模块化的代码结构。

## 软件实现
### 视频流输入模块
我们使用OpenCV库来获取视频流。可以从相机或视频文件中获取视频流，具体实现可以参考代码`xx.py`。

### 视觉分拣模块
视觉分拣模块包含三个子模块：分割、跟踪和识别。

#### 分割子模块
分割子模块的具体实现可以参考代码[parts_segment.py](detect/parts_segment.py)。该模块主要包括以下步骤：

背景建模：使用GMM（高斯混合模型）建立背景模型。

帧差法分割：将当前帧与背景模型进行比较，得到差异图像，并使用二值化方法得到目标的二值蒙版，代码实现可以参考ForegroundMask.cpp。

形态学操作：对二值蒙版进行开运算或闭运算，可以去除噪声，并将目标连接成连通域，代码实现可以参考Morphology.cpp。

连通域分析：使用连通域分析算法，如连通域标记算法或轮廓查找

## 配置项

`nozzle.yaml`指定喷嘴与零件类型之间的对应关系。

喷嘴id：0~19

零件类型：从0-67中选择一些要分类的零件

